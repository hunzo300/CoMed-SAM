<!-- # CoMed-SAM: Collaborative Medical SAM for Multi-Modality Image Segmentation

> Official PyTorch implementation of **CoMed-SAM** (Kim et al., under review)<br>

## ğŸ§  Overview

CoMed-SAM is a collaborative extension of Segment Anything Model (SAM) for multi-modal medical image segmentation. It incorporates:
- Multi-encoder architecture (per modality)
- Modality dropout during training
- Lightweight convolutional fusion
- Prompt-based segmentation inference

## ğŸ–¼ï¸ Framework

<p align="center">
  <img src="assets/model_architecture.jpg" width="800">
</p>

## ğŸ“ Dataset Preparation

We used the **IVDM3Seg** dataset for lumbar spine MRI segmentation.

You can download the dataset from the official website:

ğŸ”— [Dataset Download](https://ivdm3seg.weebly.com/data.html)
```bash
CoMed-sam_dataset/
â””â”€â”€ IVDM/
    â”œâ”€â”€ ivdm_npy_train_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â”‚   â”œâ”€â”€ 01-01.npy # shape (4, 1024, 1024)
    â”‚   â”‚   â”œâ”€â”€ 01-02.npy
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ gts/
    â”‚       â”œâ”€â”€ 01-01_1.npy # shape (1024, 1024)
    â”‚       â”œâ”€â”€ 01-01_2.npy
    â”‚       â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ ivdm_npy_val_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â”‚   â”œâ”€â”€ 09-01.npy
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ gts/
    â”‚       â”œâ”€â”€ 09-01_1.npy
    â”‚       â””â”€â”€ ...
    â”‚
    â””â”€â”€ ivdm_npy_test_dataset_1024image/
        â”œâ”€â”€ imgs/
        â”‚   â”œâ”€â”€ 13-04.npy
        â”‚   â””â”€â”€ ...
        â””â”€â”€ gts/
            â”œâ”€â”€ 13-04_1.npy
            â”œâ”€â”€ 13-04_2.npy
            â””â”€â”€ ...

```

## Installation

1. Create a virtual environment  
   ```bash
   conda env create -f environment.yml
   conda activate CoMedSAM

   ```

2. Clone this repository  
   ```bash
   git clone https://github.com/hunzo300/CoMed-SAM.git
   ```

---


## ğŸ› ï¸ How to Use

### ğŸ”§ 1. Training

To train the CoMed-SAM model with dropout-enabled multi-modality input, run:

```bash
python /CoMed-SAM/script/train/train.py
````

This script uses the specified `--tr_npy_path` and `--val_npy_path` and saves checkpoints to `./pth/`.

---

### ğŸ“Š 2. Quantitative Evaluation on All Phase Combinations

To evaluate segmentation performance across **all phase combinations** (1 to 4 modalities), run:

```bash
bash /CoMed-SAM/script/test/test.sh
```

This executes multiple test scripts like:

```text
/CoMed-SAM/script/test/test_all_combination/test_phase_count_1.py  
/CoMed-SAM/script/test/test_all_combination/test_phase_count_2.py  
/CoMed-SAM/script/test/test_all_combination/test_phase_count_3.py  
/CoMed-SAM/script/test/test_all_combination/test_phase_count_4.py  
```

---

### ğŸ” 3. Inference on Individual Samples

To perform **inference on individual IVDM samples**, including mask visualization and prediction, use:

```bash
python /CoMed-SAM/script/unit_test/unit_test.py
```

This script loads the trained CoMed-SAM model and runs it on selected test samples. -->





````markdown
# CoMed-SAM: Collaborative Medical SAM for Multi-Modality Image Segmentation

> Official PyTorch implementation of **CoMed-SAM** (Kim et al., under review)<br>

---

## ğŸ§  Overview

CoMed-SAM is a collaborative extension of Segment Anything Model (SAM) for multi-modal medical image segmentation. It incorporates:
- Multi-encoder architecture (per modality)
- Modality dropout during training
- Lightweight convolutional fusion
- Prompt-based segmentation inference

---

## ğŸ–¼ï¸ Framework

<p align="center">
  <img src="assets/model_architecture.jpg" width="800">
</p>

---

## ğŸ“ Dataset Preparation

### ğŸ©» IVDM3Seg (Lumbar Spine MRI)

We used the **IVDM3Seg** dataset for lumbar spine MRI segmentation.

You can download the dataset from the official website:

ğŸ”— [IVDM3Seg Dataset Download](https://ivdm3seg.weebly.com/data.html)

```bash
CoMed-sam_dataset/
â””â”€â”€ IVDM/
    â”œâ”€â”€ ivdm_npy_train_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â”‚   â”œâ”€â”€ 01-01.npy  # shape (4, 1024, 1024)
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ gts/
    â”‚       â”œâ”€â”€ 01-01_1.npy
    â”‚       â””â”€â”€ ...
    â”œâ”€â”€ ivdm_npy_val_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â””â”€â”€ gts/
    â””â”€â”€ ivdm_npy_test_dataset_1024image/
        â”œâ”€â”€ imgs/
        â””â”€â”€ gts/
````

---

### ğŸ©º CHAOS (Abdominal MRI â€“ T1 Dual / T2-SPIR)

We also validated CoMed-SAM on the **CHAOS** dataset (Combined Healthy Abdominal Organ Segmentation) for abdominal multi-contrast MRI segmentation.

You can download the dataset from the official challenge site:

ğŸ”— [CHAOS Dataset Download](https://chaos.grand-challenge.org/)

The CHAOS dataset directory structure should be prepared as follows:

```bash
CoMed-sam_dataset/
â””â”€â”€ CHAOS/
    â”œâ”€â”€ chaos_npy_train_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â”‚   â”œâ”€â”€ 01-01.npy   # shape (4, 1024, 1024)
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ gts/
    â”‚       â”œâ”€â”€ 01-01_1.npy
    â”‚       â””â”€â”€ ...
    â”œâ”€â”€ chaos_npy_val_dataset_1024image/
    â”‚   â”œâ”€â”€ imgs/
    â”‚   â””â”€â”€ gts/
    â””â”€â”€ chaos_npy_test_dataset_1024image/
        â”œâ”€â”€ imgs/
        â””â”€â”€ gts/
```

---

## ğŸ“¦ Pretrained Models

We provide pretrained CoMed-SAM weights for both IVDM and CHAOS datasets.

| Model                | Task                         | Download                                                                     |
| -------------------- | ---------------------------- | ---------------------------------------------------------------------------- |
| CoMed-SAM (IVDM3Seg) | Lumbar disc segmentation     | [ğŸ”— Download Weights](https://drive.google.com/file/d/XXXX/view?usp=sharing) |
| CoMed-SAM (CHAOS)    | Abdominal organ segmentation | [ğŸ”— Download Weights](https://drive.google.com/file/d/YYYY/view?usp=sharing) |


---

## ğŸ› ï¸ Installation

1. Create a virtual environment

   ```bash
   conda env create -f environment.yml
   conda activate CoMedSAM
   ```

2. Clone this repository

   ```bash
   git clone https://github.com/hunzo300/CoMed-SAM.git
   ```

---

## ğŸ§ª How to Use

### ğŸ”§ 1. Training

To train the CoMed-SAM model with modality dropout:

```bash
python /CoMed-SAM/script/{dataset}/train/train.py
```

This script uses `--tr_npy_path` and `--val_npy_path` and saves checkpoints to `./pth/`.

---

### ğŸ“Š 2. Quantitative Evaluation (All Phase Combinations)

Evaluate segmentation performance across all modality combinations (1â€“4):

```bash
bash /CoMed-SAM/script/test/test.sh
```

This executes multiple test scripts such as:

```text
/CoMed-SAM/script/{dataset}/test/test_all_combination/test_phase_count_1.py  
/CoMed-SAM/script/{dataset}/test/test_all_combination/test_phase_count_2.py  
/CoMed-SAM/script/{dataset}/test/test_all_combination/test_phase_count_3.py  
/CoMed-SAM/script/{dataset}/test/test_all_combination/test_phase_count_4.py  
```

---

### ğŸ” 3. Inference on Individual Samples

For inference on individual samples with visualization:

```bash
python /CoMed-SAM/script/{dataset}/unit_test/unit_test.py
```

This script loads the pretrained model and performs segmentation on selected test images.

---


```
